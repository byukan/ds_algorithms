{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate BFS on a graph constructed using a dictionary, where the keys represent node values and the dictionary\n",
    "# values are lists of neighboring nodes\n",
    "\n",
    "graph = {}\n",
    "graph['root'] = ['naruto', 'sasuke', 'sakura']\n",
    "graph['sasuke'] = ['itachi', 'kakashi']\n",
    "graph['naruto'] = ['jiraiya', 'kurama', 'minato']\n",
    "graph['sakura'] = ['tsunade', 'ino']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "find 2nd largest element in a binary search tree\n",
    "realize that we don't need to traverse the whole tree, which would cost O(n) time and O(h) space.  Instead, follow the path down the right child until you reach the end.  The rightmost node is the largest, which we can prove by contradiction.  The 2nd largest is either the parent of the largest or the largest node in largest node's left subtree.\n",
    "writing our function this way described above gives us O(h) time, which is O(lgn) if the tree is balanced, O(n) otherwise and O(lgn) space.  The iterative approach would bring our algorithm down to O(1) space overall.\n",
    "\n",
    "\n",
    "in one case, you could get to the 1st largest element by traversing down the right child until you hit None, in which case you'd reach the largest element.\n",
    "there are multiple possibilities for where the 2nd largest element would be.  it could be the parent of the largest, but it could also be in a different subtree entirely, and then it's not clear how we could toy around with parents/neighbors of the largest to get the 2nd largest.\n",
    "we could traverse through the tree, using depth first traversal or breadth first traversal and keep track of the largest and 2nd largest elements - store the candidate largest elements in a stack, and the 2nd largest would have index [-2].\n",
    "since we're doing DFS, time complexity is O(|V|+ |E|), which is worst case O(n), since we'd visit every node and edge.  since this is a binary search tree, we might keep track of lower and upper bounds - but i don't think we can eliminate any subtrees, because it could have children that end up being the 2nd largest element.  Space complexity is O(d), where d is the depth of the tree.  If tree is balanced, that comes to O(log_2(n)), but worst case is O(n), which occurs when we have a line of right children, and each child has one left child.  There are n/2 such nodes that depth first traversal would keep in the nodes stack, so that's O(n).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Find second largest node in BST.\n",
    "\n",
    "O(h) time, O(1) memory\n",
    "\"\"\"\n",
    "class TreeNode:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    def insert_left(self, value):\n",
    "        self.left=  TreeNode(value)\n",
    "        return self.left\n",
    "    def insert_right(self, value):\n",
    "        self.right = TreeNode(value)\n",
    "        return self.right\n",
    "\n",
    "    \n",
    "# def largest(node):\n",
    "#     while node.right:\n",
    "#         node = node.right\n",
    "#     return node\n",
    "\n",
    "# def largest(root, parent=None):\n",
    "#     if not root:\n",
    "#         raise Exception(\"tree must have at least one node\")\n",
    "#     if root.right:\n",
    "#         return largest(root.right, root)\n",
    "#     return root.value\n",
    "\n",
    "\n",
    "def second_largest(node):\n",
    "    \"\"\"\n",
    "if largest node has a left subtree, then the 2nd largest element is not necessarily the largest node's parent; however, the 2nd largest will be the largest element of the left subtree.\n",
    "\"\"\"\n",
    "\n",
    "    # traverse to parent of largest\n",
    "    while node.right.right:\n",
    "        node = node.right\n",
    "    # if largest node has no children we are done\n",
    "    #if not node.right.right and not node.right.left:\n",
    "    if not node.right.left:\n",
    "        return node\n",
    "    # otherwise, 2nd largest is the largest of the left subtree of largest\n",
    "    else:\n",
    "        return largest(node.right.left)\n",
    "    \n",
    "    \n",
    "    \n",
    "# def second_largest(root, parent=None):\n",
    "\n",
    "# we could have done:\n",
    "\n",
    "# if root.left and not root.right:\n",
    "#     return largest(root.left)\n",
    "\n",
    "# if root.right and not root.right.right and not root.right.left:\n",
    "#     return root.value  # second largest\n",
    "\n",
    "\n",
    "#     if not root or not(root.right or root.left):\n",
    "#         raise Exception(\"tree must have at least 2 nodes\")\n",
    "#     largest, parent_of_largest = largest(root)\n",
    "#     if not largest.left:\n",
    "#         return parent_of_largest\n",
    "#     else:\n",
    "#         # largest of left subtree; call largest on the left child of largest\n",
    "#         return largest(largest.left, largest)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#     def second_largest(root):\n",
    "#     \"\"\"\n",
    "#     depth first traversal, iteratively\n",
    "#     \"\"\"\n",
    "#     if not root or not(root.right and root.left):\n",
    "#         raise Exception(\"tree must have at least 2 nodes\")\n",
    "\n",
    "#     nodes = []  # store nodes as (node, value) tuples in stack\n",
    "#     largest_nodes = [root.value]  # stack of the largest values, 2nd largest is at [-2]\n",
    "    \n",
    "#     nodes.append(root)\n",
    "\n",
    "#     while nodes:\n",
    "#         node = nodes.pop()\n",
    "\n",
    "#         # check if the value is greater than the largest in our stack\n",
    "#         if node.value > largest_nodes[-1]:\n",
    "#             largest_nodes.append(node.value)\n",
    "        \n",
    "#         else:\n",
    "#             if node.left:\n",
    "#                 nodes.append(node.left)\n",
    "#             if node.right:\n",
    "#                 nodes.append(node.right)\n",
    "# #if len(largest_nodes) < 2:\n",
    "# #    return largest_nodes[0]\n",
    "# #else:\n",
    "# return largest_nodes[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to reduce memory cost on a set of urls, use a trie structure, which is like a nested dictionary where each key is \n",
    "one character; hence any shared url prefixes get stored in memory only once.  put an invalid url character like * \n",
    "at the end of each singleton url so that you know when to end - otherwise urls that are perfect substrings of \n",
    "others will get lost with the ambiguity.\n",
    "\n",
    "to check for a string's membership in the trie, descend from the root of the trie to to a leaf(*),\n",
    "checking for a node in the trie for each character in the string\n",
    "\"\"\"\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root_node = {}\n",
    "        \n",
    "    def check_present_and_add(self, word):\n",
    "        current_node = self.root_node\n",
    "        is_new_word = False\n",
    "        \n",
    "        for char in word:\n",
    "            if char not in current_node:\n",
    "                is_new_word = True\n",
    "                current_node[char] = {}\n",
    "            current_node = current_node[char]\n",
    "            \n",
    "        if \"End of word\" not in current_node:\n",
    "            is_new_word = True\n",
    "            current_node[\"End of word\"] = {}\n",
    "        \n",
    "        return is_new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_pivot(v):\n",
    "    \"\"\"\n",
    "    find the pivot, given a list of words.  We use the binary search technique, exploiting the fact that the pivot has the property that it is less than the previous element.  This algorithm cuts the number of possibilities in half at each iteration, giving us O(lgn) time, and O(1) memory.\n",
    "\n",
    "compare the mid element to endpoints to know whether to check the lhs or rhs\n",
    "    \"\"\"\n",
    "    low = 0\n",
    "    high = len(v) - 1\n",
    "    \n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        if v[mid] < v[mid+1]:\n",
    "            return v[mid]\n",
    "        elif v[mid] > low:  # search rhs\n",
    "            low = mid + 1\n",
    "        elif v[mid] > high:  # search lhs\n",
    "            high = mid - 1\n",
    "            \n",
    "    return \"could not find pivot\"\n",
    "            \n",
    "\n",
    "find_pivot(['xylophone', 'yellow squash', 'zucchini', 'apple', 'banana', 'cranberry', 'durian'])\n",
    "# find_pivot(['xylophone', 'yellow squash', 'zucchini', 'apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -5, -0.6, 3, 3.3, 1906, 2024, 2024]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quicksort\n",
    "# O(nlogn), recursively, place items to left and right of pivot\n",
    "\n",
    "def quicksort(v):\n",
    "    if len(v) < 2:\n",
    "        return v\n",
    "    else:\n",
    "        pivot = v[0]\n",
    "        lhs = [x for x in v[1:] if x <= pivot]\n",
    "        rhs = [x for x in v[1:] if x > pivot]\n",
    "        return quicksort(lhs) + [pivot] + quicksort(rhs)\n",
    "\n",
    "\n",
    "quicksort([-5, 1906, 2024, 3, 3.3, -5, -.6, 2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b2a3b3a1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compress(s):\n",
    "    \"\"\"\n",
    "    turn bbaaabbb into b2a3b3\n",
    "    \"\"\"\n",
    "    output = ''\n",
    "    prev = s[0]\n",
    "    count = 1\n",
    "    \n",
    "    for x in s[1:]:\n",
    "        if x == prev:\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            output += prev + str(count)\n",
    "            prev = x\n",
    "            count = 1\n",
    "    # append the last sequence\n",
    "    output += x + str(count)\n",
    "    return output\n",
    "    \n",
    "    \n",
    "\n",
    "compress('bbaaabbba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "given shuffled deck and half1, half2, check whether shuffled deck is the result of a single riffle\n",
    "\n",
    "the top card of shuffled deck must be the top card of either half1 or half2.  so what we can do is remove the matching cards, and then we're left with a subproblem that we can solve using the same technique.\n",
    "\n",
    "can be done in\n",
    "O(n) time, because we check every card to verify that deck is a single riffle.  O(1) memory\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# def single_riffle(d, h1, h2):\n",
    "#     # top card of shuffled deck must match top card of either hand1 or hand2\n",
    "#     # use recursion\n",
    "    \n",
    "# #     if d == h1 or d == h2:\n",
    "# #         return True\n",
    "    \n",
    "# #     if d[0] == h1[0]:\n",
    "# #         return single_riffle(d[1:], h1[1:], h2)\n",
    "# #     elif d[0] == h2[0:]:\n",
    "# #         return single_riffle(d[1:], h1, h2[1:])\n",
    "# #     else:\n",
    "# #         return False\n",
    "    \n",
    "    \n",
    "# #     if not h1:\n",
    "# #         return True\n",
    "    \n",
    "# #     for x in d:\n",
    "# #         if x == h1[0]:\n",
    "# #             h1 = h1[1:]\n",
    "# #         elif x == h2[0]:\n",
    "# #             h2 = h2[1:]\n",
    "# #         else:\n",
    "# #             return False\n",
    "# #     return True\n",
    "\n",
    "# def is_single_riffle(shuffled_deck, half1, half2):\n",
    "    \n",
    "#     # the way this function is written, it would alter the inputs.  If you didn't want to alter the inputs, we could create copies inside the function\n",
    "#     # or use list slicing, which is O(n) but a good choice since we're using recursion\n",
    "\n",
    "#     if len(shuffled_deck)==0:\n",
    "#         return True\n",
    "    \n",
    "#         # pop matching cards if the cards match\n",
    "# elif len(half1) and shuffled_deck[1] == half1[1]:\n",
    "#         is_single_riffle(shuffled_deck\n",
    "\n",
    "\n",
    "def is_single_riffle2(shuffled_deck, half1, half2):\n",
    "    # iterative solution: use pointers to track indices in half1 and half2\n",
    "    i, j = 0, 0\n",
    "    for x in shuffled_deck:\n",
    "        if i < len(half1) and x == half1[i]:\n",
    "            i += 1\n",
    "        elif j < len(half2) and x == half2[j]:\n",
    "            j += 1\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "    \n",
    "is_single_riffle2(shuffled_deck=[1, 2, 3, 4, 5, 6], half1=[1, 3, 5], half2=[2, 4, 6]), is_single_riffle2(shuffled_deck=[1, 2, 3, 4, 5, 6], half1=[1, 5, 3], half2=[2, 4, 6])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "check whether a linked list contains a cycle\n",
    "\n",
    "we might like to keep traversing through the list and if we never reach an end, then we know that the list has a cycle; however, we would also run into the issue of never knowing whether we're in a cycle, or if we haven't reached the end.\n",
    "in real life, we could tell if we're going in circles if we see familiar landmarks that we've already visited.  if we marked every visited node and find that we revisit a marked node, we'd know we're in a cycle.  For this to work, however, we'd need access to be able to mark the nodes, and we can't necessarily do that.\n",
    "We could store visited nodes in a set, and if we see a repeat, we know there's a cycle.  This method would cost O(n) memory.  Worst case is if the last node points to the head, then every node would get stored in the set.\n",
    "\n",
    "And if we mark a stationary landmark, we wouldn't know if it's at the head of the list that isn't part of the cycle.\n",
    "\n",
    "the solution involves employing a tortoise and a hare to traverse the list.  if the hare laps the tortoise, we'd know that the linked list has a cycle.\n",
    "\n",
    "O(n) time because at most hare would run around cycle twice, space is O(1)\n",
    "\n",
    "to get the first node in the cycle, consider that after k steps, tortoise is k steps behind hare, and hare is cycle_size - k steps behind tortoise\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cyclic(head):\n",
    "    \"\"\"\n",
    "    have a slow runner and a fast runner traverse the list.  The fast runner takes 2 steps at each iteration.\n",
    "    employ tortoise and hare to traverse list, if hare encounters tortoise, there is a cycle, or if hare reaches end, there is no cycle\n",
    "    race until they're equal\n",
    "    O(n) time because we traverse down the list of n nodes; O(1) memory \n",
    "    \"\"\"\n",
    "    # start at the first iteration\n",
    "    tortoise = head.next\n",
    "    hare = head.next.next\n",
    "    \n",
    "    # have them run until the hare reaches the end or the tortoise; we expect that either one of those will occur\n",
    "    while tortoise is not hare:\n",
    "        if tortoise.next:\n",
    "            tortoise = tortoise.next\n",
    "        else: return False\n",
    "        if hare.next.next:\n",
    "            hare = hare.next.next\n",
    "        else: return False\n",
    "        \n",
    "        # return False if any of them reaches an end\n",
    "        if hare.next is None or hare is None:\n",
    "            return False\n",
    "    \n",
    "    # exiting the while loop means that the two are equal, and we have a cycle\n",
    "    # if you wanted to return the number of nodes in the cycle, then once you have the two pointers equal, have them traverse the loop until the reach each other again.  The number of steps it takes until they equal each other is the size of the cycle, because at each iteration, the hare incrementally outpaces the tortoise by 1.\n",
    "#     O -> O -> O -> O <~  # yes, with an example of 6 nodes, the tortoise ended up back at the starting point and so did the hare, after 6 steps\n",
    "\n",
    "#     return True\n",
    "    # at this point, tortoise == hare\n",
    "    hare = hare.next.next\n",
    "    tortoise = tortoise.next\n",
    "    nodes_in_cycle = 1\n",
    "    while hare is not tortoise:\n",
    "        hare = hare.next.next\n",
    "        tortoise = tortoise.next\n",
    "        nodes_in_cycle += 1\n",
    "    return nodes_in_cycle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "delete a node from a singly linked list, given only a pointer to that node\n",
    "\n",
    "the idea is to replace all of the member variables of the indicated node to that of its next\n",
    "O(1) time, O(1) space, since we are merely reassigning pointers\n",
    "\"\"\"\n",
    "class LinkedListNode:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "    def insert(self, value):\n",
    "        self.next = LinkedListNode(value)\n",
    "        \n",
    "a = LinkedListNode(1)\n",
    "b = LinkedListNode(2)\n",
    "c = LinkedListNode(3)\n",
    "\n",
    "a.next = b\n",
    "b.next = c\n",
    "\n",
    "def delete_node(node):\n",
    "    \"\"\"\n",
    "    update all its member variables to that of its next\n",
    "    \"\"\"\n",
    "    if node.next.value:\n",
    "        node.value = node.next.value\n",
    "    if node.next.next:\n",
    "        node.next = node.next.next\n",
    "    # what if our node is the last one in the list?\n",
    "    if not node.next:\n",
    "        node.value = None # it's a design choice whether to raise Exception the node or just set its value to None.  Issue with this choice is that it would mess up other functions that depend on a Node's value to be None\n",
    "        #raise Exception(\"can't delete the last node with this function\")\n",
    "\n",
    "\"\"\"\n",
    "# :side effects:\n",
    "there could be bugs because any references to that node now point to the next one\n",
    "pointers to the original node's next now point to a dangling node\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "given a list of ids where every value but one appears twice, return the id that's missing its twin\n",
    "we can do this in O(n) time and O(n) memory by storing the list in a Counter object.\n",
    "We can also use the functionality of the XOR ^ operator to cancel out elements that appear in even multiples.  This method would reduce our memory costs down to O(1) space.\n",
    "\"\"\"\n",
    "# def find_singleton(ids):\n",
    "#     unique_id = 0\n",
    "#     for id in ids:\n",
    "#         unique_id ^= id\n",
    "#     return unique_id\n",
    "\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# def find_singleton(ids):\n",
    "#     counts = Counter(ids)\n",
    "#     for k, v in counts.items():\n",
    "#         if v == 1:\n",
    "#             return k\n",
    "\n",
    "def find_singleton(ids):\n",
    "    counts = {}\n",
    "    for id in ids:\n",
    "        if id in counts:\n",
    "            counts[id] += 1 \n",
    "        else:\n",
    "            counts[id] = 1\n",
    "    for k, v in counts.items():\n",
    "        if v == 1:\n",
    "            return k\n",
    "    \n",
    "    \n",
    "ids = [1, 1, 2, 2, 3, 3, 4, 4, 5, 6, 6]\n",
    "find_singleton(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxStack:\n",
    "    \"\"\"\n",
    "    has a Stack() object as member variables, and a Stack of maxes to keep track of the max values observed.  Thus, we can return the max of the stack in O(1) time at the expense of adding O(n) space to keep track of the maxes stack.\n",
    "    \n",
    "    it's not feasible to store the max value in a single variable because of the pop function, which could potentially pop off the max value, in which case we would have to iterate through every element to get the max\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.items = Stack()\n",
    "        self.maxes = Stack()\n",
    "        \n",
    "    def push(self, value):\n",
    "        \"\"\"\n",
    "        push value to maxes if it's greater than or equal to the current max; also append if self.maxes.peek() is None\n",
    "        \"\"\"\n",
    "        self.items.push(value)\n",
    "        if value >= self.maxes.peek() or self.maxes.peek() is None:\n",
    "            self.maxes.push(value)\n",
    "           \n",
    "    def pop(self):\n",
    "        popped = self.items.pop()\n",
    "        if popped == self.maxes.peek():\n",
    "            self.maxes.pop()\n",
    "        return popped\n",
    "        \n",
    "    def max(self):\n",
    "        return self.maxes.peek()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class queue:\n",
    "    \"\"\"\n",
    "    implement a queue with 2 stacks\n",
    "    idea is to have one be the in_stack, and the other the out_stack.  our queue class will have those two member variables, and the member functions, enqueue, and dequeue.\n",
    "    our two stacks will effectively mimic the queue structure because by popping off all the elements from in_stack into out_stack, we've essentially reversed the order of the elements and popping off the out_stack will give us first in first out FIFO behavior, as desired.\n",
    "    to enqueue, we simply append to the in_stack, which is a O(1) operation.\n",
    "    to dequeue, pop off the out stack, but if the out stack is empty, we need to pop all the elements from in_stack to the out_stack, if both of them are empty, raise Exception().\n",
    "\n",
    "    for a sequence of m enqueue and dequeue operations, we have O(m) time cost.  each operation is O(1), and we have m of them.  even though dequeue on an empty out_stack would have to move all the elements from in_stack, think about the accounting method to cost the time complexity per item.  The lifecycle of a node involves getting pushed onto the in_stack, popped off and pushed onto the out_stack, and then getting popped off the out_stack.  Each of these 4 operations are O(1), so the time cost per item is O(1), and for m items, we have O(m) time complexity.\n",
    "    memory cost is the same as our input data, so O(1) memory\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.in_stack = []\n",
    "        self.out_stack = []\n",
    "        \n",
    "    def enqueue(self, value):\n",
    "        self.in_stack.append(value)\n",
    "        \n",
    "    def dequeue(self, value):\n",
    "        # raise exception if both stacks are empty\n",
    "        if not self.in_stack and not self.out_stack:\n",
    "            raise Exception(\"cannot dequeue from empty queue\")\n",
    "        \n",
    "        # pop off out_stack if it's not empty\n",
    "        if self.out_stack():\n",
    "            return self.out_stack.pop()\n",
    "        else:  # out_stack is empty, refill from instack\n",
    "            while len(self.in_stack:\n",
    "                self.out_stack.append(self.in_stack.pop())\n",
    "            return self.out_stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "knapsack algorithm, dynamic programming\n",
    "given a list of cake_tuples representing (weight, value), and a max_capacity.\n",
    "return the max value we could steal by filling duffel bag with cake up to max_capacity.\n",
    "\n",
    "use dynamic programming, where we loop through the cake weights and the range of capacities from 0 to max_capacity+1, keeping track of the highest value we can obtain at the sub capacities.  outer loop is weights, inner loop is the values - going from the weight to max_capacity+1;\n",
    "update max value using the max of either the old max or the value of current cake + max value at max_capcity-weight.\n",
    "O(m*n) time, where m is the number of cakes, and n is the max_capacity.  we store the max_capcities for each sub capacity so space complexity is O(n)\n",
    "\"\"\"\n",
    "\n",
    "def max_value_given_capacity(cake_tuples, max_capacity):\n",
    "    max_value = [0] *(max_capacity+1)  # store the max value at kth capacity\n",
    "    \n",
    "    for weight, value in cake_tuples:\n",
    "        if weight == 0 and value > 0:\n",
    "            return float('inf')\n",
    "        for k in range(max_capacity + 1):  # we need to start at 0 because the new weight could be lower than previous weights, which would allow us to update lower ranges of max_values\n",
    "            if weight <= k:  # # don't have to consider if cake won't fit\n",
    "                max_value[k] = max(max_value[k], value + max_value[k-weight])\n",
    "            \n",
    "        return max_value[max_capacity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there's a way using matrix multiplication to to compute fib(n) in O(lgn) time\n",
    "# there's also a way to do it with a generator, which is even faster\n",
    "\n",
    "def fib(n):\n",
    "    \"\"\"\n",
    "    fibonacci with memoization\n",
    "    O(n) time, O(1) memory\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        return n\n",
    "    f_n_2 = 0\n",
    "    f_n_1 = 1\n",
    "    \n",
    "    for i in range(2, n+1):\n",
    "        current = f_n_2 + f_n_1\n",
    "        f_n_2 = f_n_1\n",
    "        f_n_1 = current\n",
    "        \n",
    "    return current\n",
    "\n",
    "[fib(n) for n in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "given length of flight and list of movie_lengths, find 2 different movies that add up exactly to the flight time.\n",
    "since we'd have to consider every movie time, before we could conclude False(i.e. there's no possible way to add up two movies), the best runtime would probably be O(n)\n",
    "brute force would loop through each element, pairing an element with every other element, and checking to see if they sum up to flight time.\n",
    "\n",
    "greedy approach, where we loop through once, and store all the times in a list.  at each iteration, add the time to our memo, and check if flight time - current movie is in the memo.  if it is, we can return True.\n",
    "\"\"\"\n",
    "\n",
    "#    \"\"\"\n",
    "#    brute force\n",
    "#    \"\"\"\n",
    "#    for x in movie_lengths:\n",
    "#        for y in movie_lenghts:\n",
    "#            if x + y == flight_time:\n",
    "#                return True\n",
    "#    return False\n",
    "\n",
    "\n",
    "def can_two_movies_fill_flight(flight_time, movie_lengths):\n",
    "    \"\"\"\n",
    "    O(n) time, O(n) memory\n",
    "    \"\"\"\n",
    "    runtimes = set()\n",
    "    for length in movie_lengths:\n",
    "        if flight_time - length in runtimes:\n",
    "            return True\n",
    "        runtimes.add(length)  # adding the runtime after looking for a companion movie ensures that we don't see the same movie twice\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(n, v):\n",
    "    \"\"\"\n",
    "    O(lgn) time, O(1) memory\n",
    "    \"\"\"\n",
    "    low = 0\n",
    "    high = len(v) - 1\n",
    "    \n",
    "    while low <= high:\n",
    "        mid = (low + high ) // 2\n",
    "        if n > v[mid]:  # search rhs by updating low\n",
    "            low = mid + 1\n",
    "        elif n < v[mid]:  # search lhs by updating high\n",
    "            high = mid - 1\n",
    "        elif n == v[mid]:\n",
    "            return mid  # return the index of n in the list v\n",
    "    return \"couldn't find pivot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pivot(v):\n",
    "    \"\"\"\n",
    "    find the pivot, given a list of words.  We use the binary search technique, exploiting the fact that the pivot has the property that it is less than the previous element.  This algorithm cuts the number of possibilities in half at each iteration, giving us O(lgn) time, and O(1) memory.\n",
    "\n",
    "compare the mid element to endpoints to know whether to check the lhs or rhs\n",
    "    \"\"\"\n",
    "    low = 0\n",
    "    high = len(v) - 1\n",
    "    \n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        if v[mid] < v[mid - 1]:\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
